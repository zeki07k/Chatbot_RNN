{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndata = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        data.append(os.path.join(dirname, filename))\nprint(data)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport json\nimport re\nimport tensorflow as tf\nimport random\nimport spacy\nnlp = spacy.load('en_core_web_sm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/chatbots-intent-recognition-dataset/Intent.json') as f:\n    intents = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intents","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(line):\n    line = re.sub(r'[^a-zA-z.?!\\']', ' ', line)\n    line = re.sub(r'[ ]+', ' ', line)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get text and intent title from json data\ninputs, targets = [], []\nclasses = []\nintent_doc = {}\n\nfor intent in intents['intents']:\n    if intent['intent'] not in classes:\n        classes.append(intent['intent'])\n    if intent['intent'] not in intent_doc:\n        intent_doc[intent['intent']] = []\n        \n    for text in intent['text']:\n        inputs.append(preprocessing(text))\n        targets.append(intent['intent'])\n        \n    for response in intent['responses']:\n        intent_doc[intent['intent']].append(response)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_data(input_list):\n    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n    \n    tokenizer.fit_on_texts(input_list)\n    \n    input_seq = tokenizer.texts_to_sequences(input_list)\n\n    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding='pre')\n    \n    return tokenizer, input_seq\n\n# preprocess input data\ntokenizer, input_tensor = tokenize_data(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_categorical_target(targets):\n    word={}\n    categorical_target=[]\n    counter=0\n    for trg in targets:\n        if trg not in word:\n            word[trg]=counter\n            counter+=1\n        categorical_target.append(word[trg])\n    \n    categorical_tensor = tf.keras.utils.to_categorical(categorical_target, num_classes=len(word), dtype='int32')\n    return categorical_tensor, dict((v,k) for k, v in word.items())\n\n# preprocess output data\ntarget_tensor, trg_index_word = create_categorical_target(targets)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('input shape: {} and output shape: {}'.format(input_tensor.shape, target_tensor.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameters\nepochs=50\nvocab_size=len(tokenizer.word_index) + 1\nembed_dim=512\nunits=128\ntarget_length=target_tensor.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build RNN Model with tensorflow\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embed_dim),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, dropout=0.2)),\n    tf.keras.layers.Dense(units, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(target_length, activation='softmax')\n])\n\noptimizer = tf.keras.optimizers.Adam(lr=1e-2)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n\n# train the model\nmodel.fit(input_tensor, target_tensor, epochs=epochs, callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def response(sentence):\n    sent_seq = []\n    doc = nlp(repr(sentence))\n    \n    # split the input sentences into words\n    for token in doc:\n        if token.text in tokenizer.word_index:\n            sent_seq.append(tokenizer.word_index[token.text])\n\n        # handle the unknown words error\n        else:\n            sent_seq.append(tokenizer.word_index['<unk>'])\n\n    sent_seq = tf.expand_dims(sent_seq, 0)\n    # predict the category of input sentences\n    pred = model(sent_seq)\n\n    pred_class = np.argmax(pred.numpy(), axis=1)\n    \n    # choice a random response for predicted sentence\n    return random.choice(intent_doc[trg_index_word[pred_class[0]]]), trg_index_word[pred_class[0]]\n\n# chat with bot\nprint(\"Note: Enter 'quit' to break the loop.\")\nwhile True:\n    input_ = input('You: ')\n    if input_.lower() == 'quit':\n        break\n    res, typ = response(input_)\n    print('Bot: {} -- TYPE: {}'.format(res, typ))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}